{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81cf0d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import random\n",
    "import struct\n",
    "from array import array\n",
    "from os.path  import join\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2222044",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistDataloader(object):\n",
    "    def __init__(self, training_images_filepath,training_labels_filepath,\n",
    "                 test_images_filepath, test_labels_filepath):\n",
    "        self.training_images_filepath = training_images_filepath\n",
    "        self.training_labels_filepath = training_labels_filepath\n",
    "        self.test_images_filepath = test_images_filepath\n",
    "        self.test_labels_filepath = test_labels_filepath\n",
    "\n",
    "    def read_images_labels(self, images_filepath, labels_filepath):\n",
    "        labels = []\n",
    "        with open(labels_filepath, 'rb') as file:\n",
    "            magic, size = struct.unpack(\">II\", file.read(8))\n",
    "            if magic != 2049:\n",
    "                raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
    "            labels = array(\"B\", file.read())\n",
    "\n",
    "        with open(images_filepath, 'rb') as file:\n",
    "            magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "            if magic != 2051:\n",
    "                raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "            image_data = array(\"B\", file.read())\n",
    "\n",
    "        images = []\n",
    "        for i in range(size):\n",
    "            images.append([0] * rows * cols)\n",
    "        for i in range(size):\n",
    "            img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n",
    "            img = img.reshape(28, 28)\n",
    "            images[i][:] = img\n",
    "\n",
    "        return images, labels\n",
    "\n",
    "            \n",
    "    def load_data(self):\n",
    "        x_train, y_train = self.read_images_labels(self.training_images_filepath, self.training_labels_filepath)\n",
    "        x_test, y_test = self.read_images_labels(self.test_images_filepath, self.test_labels_filepath)\n",
    "        return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4e9c4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify reading dataset via MnistDataloader class\n",
    "\n",
    "input_path = 'data/mnist'\n",
    "training_images_filepath = join(input_path, 'train-images-idx3-ubyte/train-images-idx3-ubyte')\n",
    "training_labels_filepath = join(input_path, 'train-labels-idx1-ubyte/train-labels-idx1-ubyte')\n",
    "test_images_filepath = join(input_path, 't10k-images-idx3-ubyte/t10k-images-idx3-ubyte')\n",
    "test_labels_filepath = join(input_path, 't10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte')\n",
    "\n",
    "# Helper function to show a list of images with their relating titles\n",
    "\n",
    "def show_images(images, title_texts):\n",
    "    cols = 5\n",
    "    rows = int(len(images)/cols) + 1\n",
    "    plt.figure(figsize=(30,20))\n",
    "    index = 1\n",
    "    for x in zip(images, title_texts):\n",
    "        image = x[0]\n",
    "        title_text = x[1]\n",
    "        plt.subplot(rows, cols, index)\n",
    "        plt.imshow(image, cmap=plt.cm.gray)\n",
    "        if (title_text != ''):\n",
    "            plt.title(title_text, fontsize = 15);  \n",
    "        index += 1\n",
    "\n",
    "# Load MNIST dataset\n",
    "mnist_dataloader = MnistDataloader(training_images_filepath, training_labels_filepath, \n",
    "                                   test_images_filepath, test_labels_filepath)\n",
    "(x_train, y_train), (x_test, y_test) = mnist_dataloader.load_data()\n",
    "\n",
    "\n",
    "# Show some random training and test images\n",
    "images_2_show = []\n",
    "titles_2_show = []\n",
    "for i in range(0, 10):\n",
    "    r = random.randint(1, 60000)\n",
    "    images_2_show.append(x_train[r])\n",
    "    titles_2_show.append('training image [' + str(r) + '] = ' + str(y_train[r]))\n",
    "\n",
    "for i in range(0, 5):\n",
    "    r = random.randint(1, 10000)\n",
    "    images_2_show.append(x_test[r])        \n",
    "    titles_2_show.append('test image [' + str(r) + '] = ' + str(y_test[r]))    \n",
    "\n",
    "#show_images(images_2_show, titles_2_show) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9541e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each image to a 784 length vector of uint8\n",
    "x_train = np.array(x_train, dtype=np.float32).reshape(len(x_train), -1) / 255.0   # directly as float32\n",
    "x_train = x_train.reshape(len(x_train), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "195a6154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to expected output layer activation\n",
    "gt_output = np.zeros((len(y_train), 10), dtype=np.float32)\n",
    "for label_ind in range(len(y_train)):\n",
    "    gt_output[label_ind][y_train[label_ind]] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8fea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers: slice selector and accuracy tester\n",
    "\n",
    "def select_training_slice(x, y, start=0, end=None, set_global=True):\n",
    "    \"\"\"Return (x_slice, y_slice) for x[start:end].\n",
    "    If set_global=True the function will also set `training_subset` and\n",
    "    `training_slice_start` in the notebook globals for convenience.\n",
    "    \"\"\"\n",
    "    if end is None:\n",
    "        end = len(x)\n",
    "    if not (0 <= start <= len(x)) or not (0 <= end <= len(x)):\n",
    "        raise IndexError(\"start/end out of range\")\n",
    "    if start >= end:\n",
    "        raise ValueError(\"start must be < end\")\n",
    "    x_slice = x[start:end]\n",
    "    y_slice = y[start:end]\n",
    "    if set_global:\n",
    "        globals()['training_subset'] = x_slice\n",
    "        globals()['training_slice_start'] = start\n",
    "    return x_slice, y_slice\n",
    "\n",
    "\n",
    "def _gt_to_label(gt):\n",
    "    \"\"\"Normalize ground-truth `gt` (int or one-hot vector/array) to an int label.\"\"\"\n",
    "    # If it's already an integer type, return directly\n",
    "    if isinstance(gt, (int, np.integer)):\n",
    "        return int(gt)\n",
    "    # If it's a Value or has .data, try to extract\n",
    "    if hasattr(gt, 'data'):\n",
    "        try:\n",
    "            return int(gt.data)\n",
    "        except Exception:\n",
    "            pass\n",
    "    # If it's array-like, convert and argmax\n",
    "    try:\n",
    "        arr = np.array(gt)\n",
    "        if arr.size == 1:\n",
    "            return int(arr.reshape(-1)[0])\n",
    "        return int(np.argmax(arr))\n",
    "    except Exception:\n",
    "        # final fallback\n",
    "        return int(gt)\n",
    "\n",
    "\n",
    "def test_accuracy_on_slice(model, x_slice, y_slice, verbose=False, max_display=10):\n",
    "    \"\"\"Compute accuracy of `model` on given (x_slice, y_slice).\n",
    "\n",
    "    Accepts y_slice as integers or one-hot vectors.\n",
    "    \"\"\"\n",
    "    num_correct = 0\n",
    "    total = len(x_slice)\n",
    "    for i, (img, gt) in enumerate(zip(x_slice, y_slice)):\n",
    "        yp = model(img)\n",
    "        # get numeric outputs\n",
    "        if isinstance(yp, list):\n",
    "            outputs = [float(o.data) for o in yp]\n",
    "        else:\n",
    "            outputs = [float(yp.data)]\n",
    "        pred = int(np.argmax(outputs))\n",
    "\n",
    "        gt_label = _gt_to_label(gt)\n",
    "\n",
    "        if pred == gt_label:\n",
    "            num_correct += 1\n",
    "        else:\n",
    "            if verbose and max_display > 0:\n",
    "                print(f\"idx={i} pred={pred} gt={gt_label} outputs={outputs}\")\n",
    "                max_display -= 1\n",
    "    percent = num_correct / total if total > 0 else 0.0\n",
    "    if verbose:\n",
    "        print(f\"Accuracy: {num_correct}/{total} = {percent:.4f}\")\n",
    "    return num_correct, total, percent\n",
    "\n",
    "# Example convenience wrapper that uses the notebook globals if present\n",
    "def test_accuracy_on_global_slice(model, verbose=False):\n",
    "    if 'training_subset' not in globals() or 'training_slice_start' not in globals():\n",
    "        raise RuntimeError('Call select_training_slice(...) with set_global=True first')\n",
    "    start = globals().get('training_slice_start', 0)\n",
    "    x_slice = globals()['training_subset']\n",
    "    y_slice = globals().get('y_train', None)\n",
    "    if y_slice is None:\n",
    "        # fall back to y_train in globals\n",
    "        y_slice = globals().get('y_train')\n",
    "    # if y_slice is full y_train, pick the matching range\n",
    "    if y_slice is not None and len(y_slice) == len(globals().get('x_train', [])):\n",
    "        # pick matching labels\n",
    "        end = start + len(x_slice)\n",
    "        y_slice = y_slice[start:end]\n",
    "    return test_accuracy_on_slice(model, x_slice, y_slice, verbose=verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e52d064",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value:\n",
    "\n",
    "    def __init__(self, data, _children=(), _op='', label=''):\n",
    "        # coerce scalar-ish data to Python float to avoid numpy-scalar surprises\n",
    "        try:\n",
    "            if np.isscalar(data):\n",
    "                self.data = float(data)\n",
    "            else:\n",
    "                self.data = data\n",
    "        except Exception:\n",
    "            # fallback\n",
    "            try:\n",
    "                self.data = float(data)\n",
    "            except Exception:\n",
    "                self.data = data\n",
    "\n",
    "        self.grad = 0.0\n",
    "        self._backward = lambda: None\n",
    "        self._prev = set(_children)\n",
    "        self._op = _op\n",
    "        self.label = label\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Value(data={self.data})\"\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        other = other if isinstance(other, Value) else Value(other)\n",
    "        out = Value(self.data + other.data, (self, other), '+')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += 1.0 * out.grad\n",
    "            other.grad += 1.0 * out.grad\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        other = other if isinstance(other, Value) else Value(other)\n",
    "        out = Value(self.data * other.data, (self, other), '*')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += other.data * out.grad\n",
    "            other.grad += self.data * out.grad \n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def __pow__(self, other):\n",
    "        assert isinstance(other, (int, float)), \"only supporting int/float powers for now\" \n",
    "        out = Value(self.data**other, (self, ), f'**{other}')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += other * (self.data**(other-1)) * out.grad \n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def __rmul__(self, other): # other * self\n",
    "        return self * other\n",
    "    \n",
    "    def __radd__(self, other): # other + self\n",
    "        return self + other\n",
    "\n",
    "    def __truediv__(self, other): # self / other\n",
    "        return self * other**-1\n",
    "\n",
    "    def __neg__(self): # -self\n",
    "        return self * -1\n",
    "    \n",
    "    def __sub__(self, other): # self - other\n",
    "        return self + (-other)\n",
    "\n",
    "    def tanh(self):\n",
    "        x = self.data\n",
    "        t = math.tanh(x)\n",
    "        out = Value(t, (self, ), 'tanh')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += (1- t*t) * out.grad\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def exp(self):\n",
    "        x = self.data\n",
    "        out = Value(math.exp(x), (self, ), 'exp')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += out.data * out.grad\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self):\n",
    "\n",
    "        topo = []\n",
    "        visited = set()\n",
    "        def build_topo(v):\n",
    "            if v not in visited:\n",
    "                visited.add(v)\n",
    "                for child in v._prev:\n",
    "                    build_topo(child)\n",
    "                topo.append(v)\n",
    "        build_topo(self)\n",
    "        \n",
    "        self.grad = 1.0\n",
    "        for node in reversed(topo):\n",
    "            node._backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307ca84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, nin):\n",
    "        self.w = [Value(random.uniform(-1,1)) for _ in range(nin)]\n",
    "        self.b = Value(random.uniform(-1,1))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # w * x + b\n",
    "        act = sum((wi*xi for wi, xi in zip(self.w, x)), self.b) \n",
    "        out = act.tanh()\n",
    "        return out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.w + [self.b]\n",
    "        \n",
    "class Layer:\n",
    "\n",
    "    def __init__(self, nin, nout):\n",
    "        self.neurons = [Neuron(nin) for _ in range(nout)]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        outs = [n(x) for n in self.neurons]\n",
    "        return outs[0] if len(outs) == 1 else outs\n",
    "\n",
    "    def parameters(self):\n",
    "        return [p for neuron in self.neurons for p in neuron.parameters()]\n",
    "       \n",
    "\n",
    "class MLP:\n",
    "\n",
    "    def __init__(self, nin, nouts): # nouts is a now a list, each element defines the size of each layer\n",
    "        sz = [nin] + nouts\n",
    "        self.layers = [Layer(sz[i], sz[i+1]) for i in range(len(nouts))]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a7a1252",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "def trace(root):\n",
    "    # builds a set of all nodes and edges in a graph\n",
    "    nodes, edges = set(), set()\n",
    "    def build(v):\n",
    "        if v not in nodes:\n",
    "            nodes.add(v)\n",
    "            for child in v._prev:\n",
    "                edges.add((child, v))\n",
    "                build(child)\n",
    "    build(root)\n",
    "    return nodes, edges\n",
    "\n",
    "def draw_dot(root):\n",
    "    dot = Digraph(format='svg', graph_attr={'rankdir': 'LR'}) # LR = left to right\n",
    "\n",
    "    nodes, edges = trace(root)\n",
    "    for n in nodes:\n",
    "        uid = str(id(n))\n",
    "        # for any value in the graph, create a rectangular ('record') node for it\n",
    "        dot.node(name = uid, label = \"{ %s | data %.4f | grad %.4f}\" % (n.label, n.data, n.grad), shape='record')\n",
    "        if n._op:\n",
    "            # if this value is the result of some operation, create an op node for it\n",
    "            dot.node(name = uid + n._op, label  = n._op)\n",
    "            # and connect this node to it\n",
    "            dot.edge(uid + n._op, uid)\n",
    "\n",
    "    for n1, n2 in edges:\n",
    "        # connect n1 to the op node of n2\n",
    "        dot.edge(str(id(n1)), str(id(n2)) + n2._op)\n",
    "\n",
    "    return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb1ca61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing neural network\n",
    "input_layers = 784\n",
    "output_layers = 10\n",
    "\n",
    "\n",
    "n = MLP(input_layers, [16, 16, 16, output_layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22a1f534",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:01<00:16,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.4123299967703815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:03<00:11,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4.2603954236347725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:04<00:11,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 4.1367702267848045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:06<00:08,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 4.036272020039516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:07<00:06,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 3.954621496539032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:08<00:05,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 3.8883035796414886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:10<00:04,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 3.8344426590951874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:11<00:02,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 3.790693552417045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:13<00:01,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 3.7551481116728205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:14<00:00,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 3.726256420583094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "x_train_sub, y_train_sub = select_training_slice(x_train, gt_output, 5, 10)\n",
    "\n",
    "for k in tqdm(range(10)):\n",
    "    # forward pass\n",
    "    ypred = [n(image) for image in x_train_sub] # list of output lists or Values\n",
    "\n",
    "    total_loss = Value(0.0)\n",
    "    # accumulate loss as Value objects\n",
    "    for ygt, yp in zip(y_train_sub, ypred): # ygt and yp are matching pairs\n",
    "        # ensure yp is list of Values\n",
    "        if not isinstance(yp, list):\n",
    "            yp = [yp]\n",
    "        ind_loss = Value(0.0)\n",
    "        for i in range(len(ygt)):\n",
    "            # yp[i] is Value, ygt[i] is float\n",
    "            ind_loss = ind_loss + (yp[i] - ygt[i])**2\n",
    "        total_loss = total_loss + ind_loss\n",
    "\n",
    "    # backward pass\n",
    "    for p in n.parameters():\n",
    "        p.grad = 0.0\n",
    "\n",
    "    total_loss.backward()\n",
    "\n",
    "    # update\n",
    "    lr = 0.01\n",
    "    for p in n.parameters():\n",
    "        # optional gradient clipping\n",
    "        if p.grad > 1e3:\n",
    "            p.grad = 1e3\n",
    "        if p.grad < -1e3:\n",
    "            p.grad = -1e3\n",
    "        p.data += -lr * p.grad\n",
    "\n",
    "    print(k, total_loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26c46ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only length-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m end_test = start_test + num_test_images\n\u001b[32m      5\u001b[39m x_test_sub, y_test_sub = select_training_slice(x_train, gt_output, start, end)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mtest_accuracy_on_slice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test_sub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_sub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 47\u001b[39m, in \u001b[36mtest_accuracy_on_slice\u001b[39m\u001b[34m(model, x_slice, y_slice, verbose, max_display)\u001b[39m\n\u001b[32m     45\u001b[39m     outputs = [\u001b[38;5;28mfloat\u001b[39m(yp.data)]\n\u001b[32m     46\u001b[39m pred = \u001b[38;5;28mint\u001b[39m(np.argmax(outputs))\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pred == \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgt\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     48\u001b[39m     num_correct += \u001b[32m1\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mTypeError\u001b[39m: only length-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "start_test = random.randint(0, 50000)\n",
    "num_test_images = 10\n",
    "end_test = start_test + num_test_images\n",
    "\n",
    "x_test_sub, y_test_sub = select_training_slice(x_train, gt_output, start_test, end_test)\n",
    "# y_test_sub may be one-hot; test_accuracy_on_slice handles that\n",
    "test_accuracy_on_slice(n, x_test_sub, y_test_sub, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c877afef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network parameter stats (min, max, mean, std): (np.float64(-0.05192177096451992), np.float64(0.2996647856479231), np.float64(5.8419287785319525e-05), np.float64(0.029120956672439614))\n",
      "Output values (sample): [0.09903678557529123, 0.29504612576973244, 0.09943930194454544, 0.09910253796167223, 0.19777701683305302, 0.09953046418783086, -1.6685875209578334e-05, 0.0005660990776248529, 0.000471181505220096, 0.09919801986988003]\n",
      "Backward completed\n",
      "Parameter stats after backward (min, max, mean, std): (np.float64(-0.05192177096451992), np.float64(0.2996647856479231), np.float64(5.8419287785319525e-05), np.float64(0.029120956672439614))\n",
      "Params contain inf/nan: False\n",
      "Grads contain inf/nan: False\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic: print parameter stats and run one forward/backward to detect overflow\n",
    "import math\n",
    "\n",
    "def param_stats(params):\n",
    "    vals = [p.data for p in params]\n",
    "    arr = np.array(vals, dtype=np.float64)\n",
    "    return arr.min(), arr.max(), arr.mean(), arr.std()\n",
    "\n",
    "print('Network parameter stats (min, max, mean, std):', param_stats(n.parameters()))\n",
    "\n",
    "# take one sample\n",
    "sample = x_train[0]\n",
    "label = y_train[0]\n",
    "\n",
    "# forward\n",
    "out = n(sample)\n",
    "if isinstance(out, list):\n",
    "    out_vals = [o.data for o in out]\n",
    "else:\n",
    "    out_vals = [out.data]\n",
    "print('Output values (sample):', out_vals)\n",
    "\n",
    "# compute simple loss (sum of squares to one-hot target)\n",
    "target = np.zeros(len(out_vals), dtype=np.float32)\n",
    "if isinstance(label, (int, np.integer)):\n",
    "    target[label] = 1.0\n",
    "loss = 0\n",
    "for i, o in enumerate(out_vals):\n",
    "    loss += (o - target[i])**2\n",
    "\n",
    "# set grads manually and run backward through Values if available\n",
    "# we expect out to be Value objects; set grad and call backward\n",
    "try:\n",
    "    if isinstance(out, list):\n",
    "        # set gradients on each scalar output\n",
    "        for o in out:\n",
    "            o.grad = 1.0\n",
    "            # run backward for this output\n",
    "            o.backward()\n",
    "    else:\n",
    "        out.grad = 1.0\n",
    "        out.backward()\n",
    "    print('Backward completed')\n",
    "except Exception as e:\n",
    "    print('Error during backward:', repr(e))\n",
    "\n",
    "print('Parameter stats after backward (min, max, mean, std):', param_stats(n.parameters()))\n",
    "\n",
    "# Check for inf or nan in parameters and grads\n",
    "has_inf = any(math.isinf(float(p.data)) or math.isnan(float(p.data)) for p in n.parameters())\n",
    "has_grad_inf = any(math.isinf(float(p.grad)) or math.isnan(float(p.grad)) for p in n.parameters())\n",
    "print('Params contain inf/nan:', has_inf)\n",
    "print('Grads contain inf/nan:', has_grad_inf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b0148d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
